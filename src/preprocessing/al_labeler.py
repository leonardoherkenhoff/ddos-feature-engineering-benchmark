import pandas as pd
import numpy as np
import glob
import os

"""
ALFlowLyzer Sanitizer & Topological Labeler
Cleans string artifacts generated by ALFlowLyzer in numeric fields and applies 
Ground Truth Labeling based on Network Topology.
"""

# --- CONFIGURATION ---
INPUT_DIR = "./data/interim/AL_RAW"
OUTPUT_DIR = "./data/processed/AL"
ATTACKER_IP = "172.16.0.5"

def clean_and_label(df, filename):
    """Replaces extraction error artifacts with zeros and applies topological rule."""
    # Standardize column names
    df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]
    
    # Remove extraction artifacts that break ML ingestion
    garbage = ['not a dns flow', 'not a complete handshake', 'nan', 'inf', '-inf', 'unknown']
    df.replace(garbage, 0, inplace=True)
    
    # Cast target features to numeric, retaining categorical metadata
    meta_cols = ['flow_id', 'timestamp', 'src_ip', 'src_port', 'dst_ip', 'dst_port', 'protocol', 'label']
    for col in df.columns:
        if col not in meta_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # Topological Rule Application
    src_cols = [c for c in df.columns if 'src' in c and 'ip' in c]
    if not src_cols: 
        print(f"   [WARNING] Missing IP column in {filename}.")
        return df
    
    src_col = src_cols[0]
    attack_name = os.path.basename(filename).replace('.csv', '')
    if "DrDoS_" not in attack_name and "DNS" in attack_name: attack_name = "DrDoS_DNS"
        
    df['Label'] = np.where(df[src_col] == ATTACKER_IP, attack_name, 'BENIGN')
    return df

def main():
    print("=== ALFlowLyzer Consolidation & Labeling ===")
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Search for all interim CSVs
    files = sorted(glob.glob(os.path.join(INPUT_DIR, "**", "*.csv"), recursive=True))
    if not files: return
    
    for f in files:
        try:
            filename = os.path.basename(f)
            temp_df = pd.read_csv(f, on_bad_lines='skip', low_memory=False)
            if temp_df.empty: continue
                
            clean_df = clean_and_label(temp_df, filename)
            
            # Memory optimization before save
            for col in clean_df.select_dtypes(include=['float64']).columns:
                clean_df[col] = pd.to_numeric(clean_df[col], downcast='float')
            
            rel_path = os.path.relpath(os.path.dirname(f), INPUT_DIR)
            target_dir = os.path.join(OUTPUT_DIR, rel_path)
            os.makedirs(target_dir, exist_ok=True)
            
            clean_df.to_csv(os.path.join(target_dir, filename), index=False)
            print(f"    ✅ Processed & Labeled: {filename}")
        except Exception as e:
            print(f"    ❌ Failed on {filename}: {e}")

if __name__ == "__main__":
    main()
